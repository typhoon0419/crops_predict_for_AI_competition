{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir \n",
    "from os.path import isfile, join\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 80270 files.\n",
      "folder: ['banana', 'bareland', 'carrot', 'corn', 'dragonfruit', 'garlic', 'guava', 'peanut', 'pineapple', 'pumpkin', 'rice', 'soybean', 'sugarcane', 'tomato']\n"
     ]
    }
   ],
   "source": [
    "# Searching training data\n",
    "\n",
    "label_folder = []\n",
    "total_size = 0\n",
    "data_path = r\"C:\\Users\\ESA LAB\\Desktop\\Files\\course\\110-2\\AI\\03_final\\resize_datasets\"\n",
    "\n",
    "#os.walk() generates the file names(dirpath, dirnames, filenames) \n",
    "#in a directory tree by walking the tree either top-down or bottom-up.\n",
    "for root, dirts, files in os.walk(data_path): \n",
    "    for dirt in dirts:\n",
    "        label_folder.append(dirt)\n",
    "    \n",
    "    total_size += len(files)\n",
    "\n",
    "    \n",
    "print(\"found\",total_size,\"files.\")\n",
    "print(\"folder:\",label_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80270, 256, 256, 3)\n",
      "(80270,)\n"
     ]
    }
   ],
   "source": [
    "#Load training images\n",
    "\n",
    "base_x_train = []\n",
    "base_y_train = []\n",
    "\n",
    "for i in range(len(label_folder)):\n",
    "    labelPath = data_path+r'\\\\'+label_folder[i]\n",
    "    \n",
    "    #listdir() returns a list containing the names of the entries in the directory given by path.\n",
    "    #isfile() is used to check whether the specified path is an existing regular file or not.\n",
    "    FileName = [f for f in listdir(labelPath) if isfile(join(labelPath, f))]\n",
    "    \n",
    "    for j in range(len(FileName)):\n",
    "        path = labelPath+r'\\\\'+FileName[j]\n",
    "        \n",
    "        #use cv2.imread read image.\n",
    "        img = cv2.imread(path,cv2.IMREAD_COLOR)\n",
    "        # img = img.astype('float')/255.0\n",
    "        base_x_train.append(img)\n",
    "        base_y_train.append(i)\n",
    "\n",
    "\n",
    "print(np.array(base_x_train).shape)\n",
    "print(np.array(base_y_train).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_x_train = np.array(base_x_train)\n",
    "base_x_train = base_x_train.astype('float16')/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    base_x_train, base_y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "del base_x_train, base_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), padding=\"same\", activation='relu', input_shape=(256, 256, 3)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), padding=\"same\", activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPool2D(2,2),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(128, (3, 3), padding=\"same\", activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), padding=\"same\", activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),    \n",
    "    tf.keras.layers.Conv2D(256, (3, 3), padding=\"same\", activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(256, (3, 3), padding=\"same\", activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPool2D(2,2),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Conv2D(512, (3, 3), padding=\"same\", activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(512, (3, 3), padding=\"same\", activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPool2D(4,4),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(14, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new, X_val, y_train_new, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "del X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_new = to_categorical(y_train_new)\n",
    "y_val = to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "2569/2569 [==============================] - 502s 189ms/step - loss: 5.8963 - accuracy: 0.4282 - val_loss: 2.2879 - val_accuracy: 0.4844\n",
      "Epoch 2/150\n",
      "2569/2569 [==============================] - 450s 175ms/step - loss: 1.8693 - accuracy: 0.6769 - val_loss: 2.8347 - val_accuracy: 0.4380\n",
      "Epoch 3/150\n",
      "2569/2569 [==============================] - 441s 172ms/step - loss: 0.8569 - accuracy: 0.7690 - val_loss: 0.7907 - val_accuracy: 0.7574\n",
      "Epoch 4/150\n",
      "2569/2569 [==============================] - 441s 172ms/step - loss: 0.5425 - accuracy: 0.8266 - val_loss: 0.8365 - val_accuracy: 0.7489\n",
      "Epoch 5/150\n",
      "2569/2569 [==============================] - 441s 172ms/step - loss: 0.4331 - accuracy: 0.8593 - val_loss: 0.8392 - val_accuracy: 0.7553\n",
      "Epoch 6/150\n",
      "2569/2569 [==============================] - 441s 172ms/step - loss: 0.3466 - accuracy: 0.8870 - val_loss: 0.7614 - val_accuracy: 0.7651\n",
      "Epoch 7/150\n",
      "2569/2569 [==============================] - 441s 172ms/step - loss: 0.2969 - accuracy: 0.9019 - val_loss: 0.8301 - val_accuracy: 0.7910\n",
      "Epoch 8/150\n",
      "2569/2569 [==============================] - 442s 172ms/step - loss: 0.2538 - accuracy: 0.9161 - val_loss: 0.6652 - val_accuracy: 0.8268\n",
      "Epoch 9/150\n",
      "2569/2569 [==============================] - 444s 173ms/step - loss: 0.2229 - accuracy: 0.9261 - val_loss: 1.3453 - val_accuracy: 0.7312\n",
      "Epoch 10/150\n",
      "2569/2569 [==============================] - 442s 172ms/step - loss: 0.1956 - accuracy: 0.9356 - val_loss: 0.4618 - val_accuracy: 0.8780\n",
      "Epoch 11/150\n",
      "2569/2569 [==============================] - 441s 172ms/step - loss: 0.1750 - accuracy: 0.9411 - val_loss: 0.4570 - val_accuracy: 0.8792\n",
      "Epoch 12/150\n",
      "2569/2569 [==============================] - 442s 172ms/step - loss: 0.1588 - accuracy: 0.9475 - val_loss: 0.5210 - val_accuracy: 0.8564\n",
      "Epoch 13/150\n",
      "2569/2569 [==============================] - 442s 172ms/step - loss: 0.1448 - accuracy: 0.9519 - val_loss: 0.3587 - val_accuracy: 0.9031\n",
      "Epoch 14/150\n",
      "2569/2569 [==============================] - 442s 172ms/step - loss: 0.1279 - accuracy: 0.9560 - val_loss: 0.3344 - val_accuracy: 0.9152\n",
      "Epoch 15/150\n",
      "2569/2569 [==============================] - 443s 172ms/step - loss: 0.1201 - accuracy: 0.9598 - val_loss: 0.4076 - val_accuracy: 0.8898\n",
      "Epoch 16/150\n",
      "2569/2569 [==============================] - 442s 172ms/step - loss: 0.1118 - accuracy: 0.9627 - val_loss: 0.3417 - val_accuracy: 0.9075\n",
      "Epoch 17/150\n",
      "2569/2569 [==============================] - 442s 172ms/step - loss: 0.1041 - accuracy: 0.9649 - val_loss: 0.5014 - val_accuracy: 0.8682\n",
      "Epoch 18/150\n",
      "2569/2569 [==============================] - 441s 172ms/step - loss: 0.0998 - accuracy: 0.9663 - val_loss: 0.5442 - val_accuracy: 0.8853\n",
      "Epoch 19/150\n",
      "2569/2569 [==============================] - 442s 172ms/step - loss: 0.0915 - accuracy: 0.9682 - val_loss: 0.4056 - val_accuracy: 0.9043\n",
      "Epoch 20/150\n",
      "2569/2569 [==============================] - 442s 172ms/step - loss: 0.0866 - accuracy: 0.9717 - val_loss: 0.4062 - val_accuracy: 0.9181\n",
      "Epoch 21/150\n",
      "2569/2569 [==============================] - 441s 172ms/step - loss: 0.0827 - accuracy: 0.9728 - val_loss: 0.5138 - val_accuracy: 0.9182\n",
      "Epoch 22/150\n",
      "2569/2569 [==============================] - 441s 172ms/step - loss: 0.0822 - accuracy: 0.9731 - val_loss: 0.3182 - val_accuracy: 0.9290\n",
      "Epoch 23/150\n",
      "2569/2569 [==============================] - 442s 172ms/step - loss: 0.0775 - accuracy: 0.9738 - val_loss: 0.4878 - val_accuracy: 0.9056\n",
      "Epoch 24/150\n",
      "2569/2569 [==============================] - 442s 172ms/step - loss: 0.0765 - accuracy: 0.9748 - val_loss: 0.3193 - val_accuracy: 0.9305\n",
      "Epoch 25/150\n",
      "2569/2569 [==============================] - 442s 172ms/step - loss: 0.0734 - accuracy: 0.9764 - val_loss: 0.3819 - val_accuracy: 0.9165\n",
      "Epoch 26/150\n",
      "2569/2569 [==============================] - 442s 172ms/step - loss: 0.0661 - accuracy: 0.9788 - val_loss: 0.4882 - val_accuracy: 0.8981\n",
      "Epoch 27/150\n",
      "2569/2569 [==============================] - 450s 175ms/step - loss: 0.0683 - accuracy: 0.9782 - val_loss: 0.3805 - val_accuracy: 0.9287\n",
      "Epoch 28/150\n",
      "2569/2569 [==============================] - 459s 179ms/step - loss: 0.0651 - accuracy: 0.9789 - val_loss: 0.4373 - val_accuracy: 0.9169\n",
      "Epoch 29/150\n",
      "2569/2569 [==============================] - 462s 180ms/step - loss: 0.0618 - accuracy: 0.9807 - val_loss: 0.3063 - val_accuracy: 0.9359\n",
      "Epoch 30/150\n",
      "2569/2569 [==============================] - 458s 178ms/step - loss: 0.0641 - accuracy: 0.9808 - val_loss: 0.5262 - val_accuracy: 0.9040\n",
      "Epoch 31/150\n",
      "2569/2569 [==============================] - 461s 179ms/step - loss: 0.0658 - accuracy: 0.9792 - val_loss: 0.3176 - val_accuracy: 0.9312\n",
      "Epoch 32/150\n",
      "2569/2569 [==============================] - 435s 169ms/step - loss: 0.0551 - accuracy: 0.9826 - val_loss: 0.4269 - val_accuracy: 0.9227\n",
      "Epoch 33/150\n",
      "2569/2569 [==============================] - 445s 173ms/step - loss: 0.0609 - accuracy: 0.9815 - val_loss: 0.3829 - val_accuracy: 0.9317\n",
      "Epoch 34/150\n",
      "2569/2569 [==============================] - 430s 167ms/step - loss: 0.0593 - accuracy: 0.9821 - val_loss: 0.5779 - val_accuracy: 0.8896\n",
      "Epoch 35/150\n",
      "2569/2569 [==============================] - 447s 174ms/step - loss: 0.0516 - accuracy: 0.9836 - val_loss: 0.5099 - val_accuracy: 0.9247\n",
      "Epoch 36/150\n",
      "2569/2569 [==============================] - 438s 170ms/step - loss: 0.0554 - accuracy: 0.9831 - val_loss: 0.4136 - val_accuracy: 0.9319\n",
      "Epoch 37/150\n",
      "2569/2569 [==============================] - 419s 163ms/step - loss: 0.0519 - accuracy: 0.9833 - val_loss: 0.3744 - val_accuracy: 0.9341\n",
      "Epoch 38/150\n",
      "2569/2569 [==============================] - 420s 163ms/step - loss: 0.0520 - accuracy: 0.9845 - val_loss: 0.4003 - val_accuracy: 0.9291\n",
      "Epoch 39/150\n",
      "2569/2569 [==============================] - 421s 164ms/step - loss: 0.0535 - accuracy: 0.9843 - val_loss: 0.3735 - val_accuracy: 0.9346\n",
      "Epoch 40/150\n",
      "2569/2569 [==============================] - 437s 170ms/step - loss: 0.0526 - accuracy: 0.9852 - val_loss: 0.3853 - val_accuracy: 0.9329\n",
      "Epoch 41/150\n",
      "2569/2569 [==============================] - 429s 167ms/step - loss: 0.0482 - accuracy: 0.9854 - val_loss: 0.3798 - val_accuracy: 0.9345\n",
      "Epoch 42/150\n",
      "2569/2569 [==============================] - 426s 166ms/step - loss: 0.0484 - accuracy: 0.9857 - val_loss: 0.4655 - val_accuracy: 0.9170\n",
      "Epoch 43/150\n",
      "2569/2569 [==============================] - 433s 169ms/step - loss: 0.0533 - accuracy: 0.9846 - val_loss: 0.3842 - val_accuracy: 0.9393\n",
      "Epoch 44/150\n",
      "2569/2569 [==============================] - 415s 162ms/step - loss: 0.0451 - accuracy: 0.9867 - val_loss: 0.3995 - val_accuracy: 0.9344\n",
      "Epoch 45/150\n",
      "2569/2569 [==============================] - 419s 163ms/step - loss: 0.0522 - accuracy: 0.9853 - val_loss: 0.3813 - val_accuracy: 0.9360\n",
      "Epoch 46/150\n",
      "2569/2569 [==============================] - 420s 163ms/step - loss: 0.0502 - accuracy: 0.9860 - val_loss: 0.4773 - val_accuracy: 0.9257\n",
      "Epoch 47/150\n",
      "2569/2569 [==============================] - 419s 163ms/step - loss: 0.0470 - accuracy: 0.9869 - val_loss: 0.4087 - val_accuracy: 0.9377\n",
      "Epoch 48/150\n",
      "2569/2569 [==============================] - 420s 164ms/step - loss: 0.0516 - accuracy: 0.9855 - val_loss: 0.3674 - val_accuracy: 0.9422\n",
      "Epoch 49/150\n",
      "2569/2569 [==============================] - 418s 163ms/step - loss: 0.0447 - accuracy: 0.9875 - val_loss: 0.4523 - val_accuracy: 0.9351\n",
      "Epoch 50/150\n",
      "2569/2569 [==============================] - 421s 164ms/step - loss: 0.0465 - accuracy: 0.9873 - val_loss: 0.4139 - val_accuracy: 0.9418\n",
      "Epoch 51/150\n",
      "2569/2569 [==============================] - 420s 163ms/step - loss: 0.0463 - accuracy: 0.9876 - val_loss: 0.3912 - val_accuracy: 0.9391\n",
      "Epoch 52/150\n",
      "2569/2569 [==============================] - 441s 172ms/step - loss: 0.0459 - accuracy: 0.9878 - val_loss: 0.5276 - val_accuracy: 0.9282\n",
      "Epoch 53/150\n",
      "2569/2569 [==============================] - 426s 166ms/step - loss: 0.0426 - accuracy: 0.9880 - val_loss: 0.5627 - val_accuracy: 0.9263\n",
      "Epoch 54/150\n",
      "2569/2569 [==============================] - 428s 167ms/step - loss: 0.0459 - accuracy: 0.9877 - val_loss: 0.3567 - val_accuracy: 0.9417\n",
      "Epoch 55/150\n",
      "2569/2569 [==============================] - 426s 166ms/step - loss: 0.0428 - accuracy: 0.9885 - val_loss: 0.3681 - val_accuracy: 0.9449\n",
      "Epoch 56/150\n",
      "2569/2569 [==============================] - 431s 168ms/step - loss: 0.0446 - accuracy: 0.9891 - val_loss: 0.4365 - val_accuracy: 0.9355\n",
      "Epoch 57/150\n",
      "2569/2569 [==============================] - 428s 167ms/step - loss: 0.0435 - accuracy: 0.9888 - val_loss: 0.4418 - val_accuracy: 0.9365\n",
      "Epoch 58/150\n",
      "2569/2569 [==============================] - 426s 166ms/step - loss: 0.0424 - accuracy: 0.9883 - val_loss: 0.4698 - val_accuracy: 0.9344\n",
      "Epoch 59/150\n",
      "2569/2569 [==============================] - 427s 166ms/step - loss: 0.0433 - accuracy: 0.9888 - val_loss: 0.4108 - val_accuracy: 0.9366\n",
      "Epoch 60/150\n",
      "2569/2569 [==============================] - 429s 167ms/step - loss: 0.0420 - accuracy: 0.9887 - val_loss: 0.3525 - val_accuracy: 0.9457\n",
      "Epoch 61/150\n",
      "2569/2569 [==============================] - 429s 167ms/step - loss: 0.0424 - accuracy: 0.9890 - val_loss: 0.4587 - val_accuracy: 0.9373\n",
      "Epoch 62/150\n",
      "2569/2569 [==============================] - 424s 165ms/step - loss: 0.0394 - accuracy: 0.9893 - val_loss: 0.4333 - val_accuracy: 0.9424\n",
      "Epoch 63/150\n",
      "2569/2569 [==============================] - 426s 166ms/step - loss: 0.0397 - accuracy: 0.9893 - val_loss: 0.3942 - val_accuracy: 0.9473\n",
      "Epoch 64/150\n",
      "2569/2569 [==============================] - 430s 167ms/step - loss: 0.0430 - accuracy: 0.9894 - val_loss: 0.4346 - val_accuracy: 0.9436\n",
      "Epoch 65/150\n",
      "2569/2569 [==============================] - 430s 167ms/step - loss: 0.0425 - accuracy: 0.9904 - val_loss: 0.5492 - val_accuracy: 0.9337\n",
      "Epoch 66/150\n",
      "2569/2569 [==============================] - 421s 164ms/step - loss: 0.0390 - accuracy: 0.9899 - val_loss: 0.5671 - val_accuracy: 0.9292\n",
      "Epoch 67/150\n",
      "2569/2569 [==============================] - 428s 166ms/step - loss: 0.0413 - accuracy: 0.9897 - val_loss: 0.4800 - val_accuracy: 0.9408\n",
      "Epoch 68/150\n",
      "2569/2569 [==============================] - 421s 164ms/step - loss: 0.0379 - accuracy: 0.9907 - val_loss: 0.5267 - val_accuracy: 0.9371\n",
      "Epoch 69/150\n",
      "2569/2569 [==============================] - 416s 162ms/step - loss: 0.0394 - accuracy: 0.9898 - val_loss: 0.5019 - val_accuracy: 0.9330\n",
      "Epoch 70/150\n",
      "2569/2569 [==============================] - 444s 173ms/step - loss: 0.0390 - accuracy: 0.9903 - val_loss: 0.5055 - val_accuracy: 0.9338\n",
      "Epoch 71/150\n",
      "2569/2569 [==============================] - 430s 168ms/step - loss: 0.0393 - accuracy: 0.9902 - val_loss: 0.5033 - val_accuracy: 0.9453\n",
      "Epoch 72/150\n",
      "2569/2569 [==============================] - 442s 172ms/step - loss: 0.0422 - accuracy: 0.9903 - val_loss: 0.4843 - val_accuracy: 0.9424\n",
      "Epoch 73/150\n",
      "2569/2569 [==============================] - 446s 174ms/step - loss: 0.0369 - accuracy: 0.9909 - val_loss: 0.4983 - val_accuracy: 0.9429\n",
      "Epoch 74/150\n",
      "2569/2569 [==============================] - 433s 169ms/step - loss: 0.0399 - accuracy: 0.9909 - val_loss: 0.5243 - val_accuracy: 0.9371\n",
      "Epoch 75/150\n",
      "2569/2569 [==============================] - 431s 168ms/step - loss: 0.0432 - accuracy: 0.9897 - val_loss: 0.5165 - val_accuracy: 0.9411\n",
      "Epoch 76/150\n",
      "2569/2569 [==============================] - 440s 171ms/step - loss: 0.0381 - accuracy: 0.9911 - val_loss: 0.4706 - val_accuracy: 0.9459\n",
      "Epoch 77/150\n",
      "2569/2569 [==============================] - 440s 171ms/step - loss: 0.0393 - accuracy: 0.9908 - val_loss: 0.4629 - val_accuracy: 0.9460\n",
      "Epoch 78/150\n",
      "2569/2569 [==============================] - 441s 172ms/step - loss: 0.0359 - accuracy: 0.9910 - val_loss: 0.5612 - val_accuracy: 0.9367\n",
      "Epoch 79/150\n",
      "2569/2569 [==============================] - 441s 172ms/step - loss: 0.0354 - accuracy: 0.9918 - val_loss: 0.4831 - val_accuracy: 0.9466\n",
      "Epoch 80/150\n",
      "2569/2569 [==============================] - 439s 171ms/step - loss: 0.0389 - accuracy: 0.9909 - val_loss: 0.5961 - val_accuracy: 0.9371\n",
      "Epoch 81/150\n",
      "2569/2569 [==============================] - 440s 171ms/step - loss: 0.0377 - accuracy: 0.9913 - val_loss: 0.6403 - val_accuracy: 0.9376\n",
      "Epoch 82/150\n",
      "2569/2569 [==============================] - 441s 172ms/step - loss: 0.0458 - accuracy: 0.9902 - val_loss: 0.5452 - val_accuracy: 0.9402\n",
      "Epoch 83/150\n",
      "2569/2569 [==============================] - 440s 171ms/step - loss: 0.0389 - accuracy: 0.9913 - val_loss: 0.5754 - val_accuracy: 0.9387\n",
      "Epoch 84/150\n",
      "2569/2569 [==============================] - 440s 171ms/step - loss: 0.0375 - accuracy: 0.9918 - val_loss: 0.5177 - val_accuracy: 0.9433\n",
      "Epoch 85/150\n",
      "2569/2569 [==============================] - 441s 172ms/step - loss: 0.0382 - accuracy: 0.9916 - val_loss: 0.5036 - val_accuracy: 0.9465\n",
      "Epoch 86/150\n",
      "2569/2569 [==============================] - 441s 172ms/step - loss: 0.0367 - accuracy: 0.9917 - val_loss: 0.5615 - val_accuracy: 0.9455\n",
      "Epoch 87/150\n",
      "2569/2569 [==============================] - 440s 171ms/step - loss: 0.0381 - accuracy: 0.9913 - val_loss: 0.5647 - val_accuracy: 0.9430\n",
      "Epoch 88/150\n",
      "2569/2569 [==============================] - 439s 171ms/step - loss: 0.0396 - accuracy: 0.9917 - val_loss: 0.7705 - val_accuracy: 0.9302\n",
      "Epoch 89/150\n",
      "2569/2569 [==============================] - 441s 171ms/step - loss: 0.0369 - accuracy: 0.9917 - val_loss: 0.5051 - val_accuracy: 0.9455\n",
      "Epoch 90/150\n",
      "2569/2569 [==============================] - 441s 172ms/step - loss: 0.0365 - accuracy: 0.9922 - val_loss: 0.6696 - val_accuracy: 0.9383\n",
      "Epoch 91/150\n",
      "2569/2569 [==============================] - 440s 171ms/step - loss: 0.0385 - accuracy: 0.9918 - val_loss: 0.6296 - val_accuracy: 0.9415\n",
      "Epoch 92/150\n",
      "2569/2569 [==============================] - 440s 171ms/step - loss: 0.0362 - accuracy: 0.9918 - val_loss: 0.5158 - val_accuracy: 0.9471\n",
      "Epoch 93/150\n",
      "2569/2569 [==============================] - 441s 171ms/step - loss: 0.0396 - accuracy: 0.9918 - val_loss: 0.5510 - val_accuracy: 0.9481\n",
      "Epoch 94/150\n",
      "2569/2569 [==============================] - 441s 172ms/step - loss: 0.0323 - accuracy: 0.9929 - val_loss: 0.6986 - val_accuracy: 0.9318\n",
      "Epoch 95/150\n",
      "2569/2569 [==============================] - 441s 171ms/step - loss: 0.0411 - accuracy: 0.9915 - val_loss: 0.5826 - val_accuracy: 0.9453\n",
      "Epoch 96/150\n",
      "2569/2569 [==============================] - 440s 171ms/step - loss: 0.0373 - accuracy: 0.9928 - val_loss: 0.5673 - val_accuracy: 0.9431\n",
      "Epoch 97/150\n",
      "2569/2569 [==============================] - 440s 171ms/step - loss: 0.0371 - accuracy: 0.9921 - val_loss: 0.5557 - val_accuracy: 0.9478\n",
      "Epoch 98/150\n",
      "2569/2569 [==============================] - 439s 171ms/step - loss: 0.0345 - accuracy: 0.9923 - val_loss: 0.5473 - val_accuracy: 0.9460\n",
      "Epoch 99/150\n",
      "2569/2569 [==============================] - 440s 171ms/step - loss: 0.0367 - accuracy: 0.9927 - val_loss: 0.6361 - val_accuracy: 0.9456\n",
      "Epoch 100/150\n",
      "2569/2569 [==============================] - 440s 171ms/step - loss: 0.0365 - accuracy: 0.9926 - val_loss: 0.6947 - val_accuracy: 0.9380\n",
      "Epoch 101/150\n",
      "2569/2569 [==============================] - 441s 171ms/step - loss: 0.0421 - accuracy: 0.9920 - val_loss: 0.5578 - val_accuracy: 0.9490\n",
      "Epoch 102/150\n",
      "2569/2569 [==============================] - 440s 171ms/step - loss: 0.0347 - accuracy: 0.9932 - val_loss: 0.6638 - val_accuracy: 0.9470\n",
      "Epoch 103/150\n",
      "2569/2569 [==============================] - 439s 171ms/step - loss: 0.0319 - accuracy: 0.9932 - val_loss: 0.5847 - val_accuracy: 0.9464\n",
      "Epoch 104/150\n",
      "2569/2569 [==============================] - 446s 174ms/step - loss: 0.0430 - accuracy: 0.9923 - val_loss: 0.5573 - val_accuracy: 0.9511\n",
      "Epoch 105/150\n",
      "2569/2569 [==============================] - 443s 172ms/step - loss: 0.0318 - accuracy: 0.9934 - val_loss: 0.6645 - val_accuracy: 0.9410\n",
      "Epoch 106/150\n",
      "2569/2569 [==============================] - 441s 172ms/step - loss: 0.0343 - accuracy: 0.9934 - val_loss: 0.6167 - val_accuracy: 0.9457\n",
      "Epoch 107/150\n",
      "2569/2569 [==============================] - 447s 174ms/step - loss: 0.0383 - accuracy: 0.9925 - val_loss: 0.7231 - val_accuracy: 0.9429\n",
      "Epoch 108/150\n",
      "2569/2569 [==============================] - 441s 172ms/step - loss: 0.0317 - accuracy: 0.9934 - val_loss: 0.6152 - val_accuracy: 0.9427\n",
      "Epoch 109/150\n",
      "2569/2569 [==============================] - 441s 172ms/step - loss: 0.0289 - accuracy: 0.9938 - val_loss: 0.7093 - val_accuracy: 0.9464\n",
      "Epoch 110/150\n",
      "2569/2569 [==============================] - 443s 173ms/step - loss: 0.0431 - accuracy: 0.9923 - val_loss: 0.5949 - val_accuracy: 0.9507\n",
      "Epoch 111/150\n",
      "2569/2569 [==============================] - 441s 172ms/step - loss: 0.0341 - accuracy: 0.9936 - val_loss: 0.5911 - val_accuracy: 0.9452\n",
      "Epoch 112/150\n",
      "2569/2569 [==============================] - 442s 172ms/step - loss: 0.0387 - accuracy: 0.9929 - val_loss: 0.6156 - val_accuracy: 0.9429\n",
      "Epoch 113/150\n",
      "2569/2569 [==============================] - 441s 172ms/step - loss: 0.0308 - accuracy: 0.9941 - val_loss: 0.7228 - val_accuracy: 0.9493\n",
      "Epoch 114/150\n",
      "2569/2569 [==============================] - 441s 172ms/step - loss: 0.0374 - accuracy: 0.9927 - val_loss: 0.7356 - val_accuracy: 0.9411\n",
      "Epoch 115/150\n",
      "2569/2569 [==============================] - 442s 172ms/step - loss: 0.0381 - accuracy: 0.9935 - val_loss: 0.6116 - val_accuracy: 0.9509\n",
      "Epoch 116/150\n",
      "2569/2569 [==============================] - 443s 172ms/step - loss: 0.0341 - accuracy: 0.9936 - val_loss: 0.6865 - val_accuracy: 0.9450\n",
      "Epoch 117/150\n",
      "2569/2569 [==============================] - 442s 172ms/step - loss: 0.0363 - accuracy: 0.9935 - val_loss: 0.9485 - val_accuracy: 0.9256\n",
      "Epoch 118/150\n",
      "2569/2569 [==============================] - 442s 172ms/step - loss: 0.0349 - accuracy: 0.9938 - val_loss: 0.6206 - val_accuracy: 0.9469\n",
      "Epoch 119/150\n",
      "2569/2569 [==============================] - 442s 172ms/step - loss: 0.0338 - accuracy: 0.9937 - val_loss: 0.7128 - val_accuracy: 0.9476\n",
      "Epoch 120/150\n",
      "2569/2569 [==============================] - 442s 172ms/step - loss: 0.0371 - accuracy: 0.9935 - val_loss: 0.5659 - val_accuracy: 0.9548\n",
      "Epoch 121/150\n",
      "2569/2569 [==============================] - 441s 172ms/step - loss: 0.0392 - accuracy: 0.9935 - val_loss: 0.8279 - val_accuracy: 0.9351\n",
      "Epoch 122/150\n",
      "2569/2569 [==============================] - 442s 172ms/step - loss: 0.0332 - accuracy: 0.9936 - val_loss: 0.6605 - val_accuracy: 0.9464\n",
      "Epoch 123/150\n",
      "2569/2569 [==============================] - 442s 172ms/step - loss: 0.0344 - accuracy: 0.9938 - val_loss: 0.6900 - val_accuracy: 0.9430\n",
      "Epoch 124/150\n",
      "2569/2569 [==============================] - 441s 172ms/step - loss: 0.0351 - accuracy: 0.9940 - val_loss: 0.7312 - val_accuracy: 0.9473\n",
      "Epoch 125/150\n",
      "2569/2569 [==============================] - 442s 172ms/step - loss: 0.0346 - accuracy: 0.9940 - val_loss: 0.7795 - val_accuracy: 0.9436\n",
      "Epoch 126/150\n",
      "2569/2569 [==============================] - 442s 172ms/step - loss: 0.0303 - accuracy: 0.9945 - val_loss: 0.9519 - val_accuracy: 0.9320\n",
      "Epoch 127/150\n",
      "2569/2569 [==============================] - 443s 172ms/step - loss: 0.0375 - accuracy: 0.9936 - val_loss: 0.6904 - val_accuracy: 0.9456\n",
      "Epoch 128/150\n",
      "2569/2569 [==============================] - 443s 173ms/step - loss: 0.0351 - accuracy: 0.9938 - val_loss: 0.6207 - val_accuracy: 0.9537\n",
      "Epoch 129/150\n",
      "2569/2569 [==============================] - 442s 172ms/step - loss: 0.0360 - accuracy: 0.9941 - val_loss: 0.7314 - val_accuracy: 0.9442\n",
      "Epoch 130/150\n",
      "2569/2569 [==============================] - 442s 172ms/step - loss: 0.0357 - accuracy: 0.9943 - val_loss: 0.6725 - val_accuracy: 0.9475\n",
      "Epoch 131/150\n",
      "2569/2569 [==============================] - 442s 172ms/step - loss: 0.0362 - accuracy: 0.9941 - val_loss: 0.7006 - val_accuracy: 0.9457\n",
      "Epoch 132/150\n",
      "2569/2569 [==============================] - 442s 172ms/step - loss: 0.0360 - accuracy: 0.9941 - val_loss: 0.7941 - val_accuracy: 0.9422\n",
      "Epoch 133/150\n",
      "2569/2569 [==============================] - 443s 172ms/step - loss: 0.0361 - accuracy: 0.9940 - val_loss: 0.7437 - val_accuracy: 0.9473\n",
      "Epoch 134/150\n",
      "2569/2569 [==============================] - 443s 172ms/step - loss: 0.0372 - accuracy: 0.9939 - val_loss: 0.7440 - val_accuracy: 0.9471\n",
      "Epoch 135/150\n",
      "2569/2569 [==============================] - 442s 172ms/step - loss: 0.0368 - accuracy: 0.9938 - val_loss: 0.8074 - val_accuracy: 0.9404\n",
      "Epoch 136/150\n",
      "2569/2569 [==============================] - 442s 172ms/step - loss: 0.0364 - accuracy: 0.9941 - val_loss: 0.6596 - val_accuracy: 0.9513\n",
      "Epoch 137/150\n",
      "2569/2569 [==============================] - 442s 172ms/step - loss: 0.0377 - accuracy: 0.9937 - val_loss: 0.7801 - val_accuracy: 0.9429\n",
      "Epoch 138/150\n",
      "2569/2569 [==============================] - 442s 172ms/step - loss: 0.0369 - accuracy: 0.9940 - val_loss: 0.8342 - val_accuracy: 0.9398\n",
      "Epoch 139/150\n",
      "2569/2569 [==============================] - 442s 172ms/step - loss: 0.0363 - accuracy: 0.9939 - val_loss: 1.2097 - val_accuracy: 0.9079\n",
      "Epoch 140/150\n",
      "2569/2569 [==============================] - 443s 172ms/step - loss: 0.0310 - accuracy: 0.9944 - val_loss: 0.7789 - val_accuracy: 0.9453\n",
      "Epoch 141/150\n",
      "2569/2569 [==============================] - 443s 172ms/step - loss: 0.0356 - accuracy: 0.9949 - val_loss: 0.6781 - val_accuracy: 0.9531\n",
      "Epoch 142/150\n",
      "2569/2569 [==============================] - 441s 172ms/step - loss: 0.0330 - accuracy: 0.9942 - val_loss: 0.7130 - val_accuracy: 0.9507\n",
      "Epoch 143/150\n",
      "2569/2569 [==============================] - 442s 172ms/step - loss: 0.0343 - accuracy: 0.9943 - val_loss: 0.8617 - val_accuracy: 0.9381\n",
      "Epoch 144/150\n",
      "2569/2569 [==============================] - 448s 174ms/step - loss: 0.0401 - accuracy: 0.9938 - val_loss: 0.7348 - val_accuracy: 0.9471\n",
      "Epoch 145/150\n",
      "2569/2569 [==============================] - 442s 172ms/step - loss: 0.0333 - accuracy: 0.9945 - val_loss: 1.0203 - val_accuracy: 0.9386\n",
      "Epoch 146/150\n",
      "2569/2569 [==============================] - 442s 172ms/step - loss: 0.0339 - accuracy: 0.9946 - val_loss: 0.7491 - val_accuracy: 0.9491\n",
      "Epoch 147/150\n",
      "2569/2569 [==============================] - 442s 172ms/step - loss: 0.0387 - accuracy: 0.9937 - val_loss: 0.8003 - val_accuracy: 0.9475\n",
      "Epoch 148/150\n",
      "2569/2569 [==============================] - 442s 172ms/step - loss: 0.0308 - accuracy: 0.9953 - val_loss: 0.7423 - val_accuracy: 0.9525\n",
      "Epoch 149/150\n",
      "2569/2569 [==============================] - 443s 172ms/step - loss: 0.0378 - accuracy: 0.9943 - val_loss: 0.8293 - val_accuracy: 0.9501\n",
      "Epoch 150/150\n",
      "2569/2569 [==============================] - 444s 173ms/step - loss: 0.0318 - accuracy: 0.9948 - val_loss: 0.9163 - val_accuracy: 0.9434\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "history = model.fit(\n",
    "    X_train_new,\n",
    "    y_train_new,\n",
    "    epochs=150,\n",
    "    batch_size=20,\n",
    "    validation_data=(X_val, y_val)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model.hdf5\")\n",
    "model.save_weights(\"model.weight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(X_test)\n",
    "prediction = np.argmax(prediction, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94.44375233586645"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, prediction)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = load_model('my_model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction1 = model1.predict(X_test)\n",
    "prediction1 = np.argmax(prediction1, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94.44375233586645"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, prediction1)*100"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8986fb416174cc2474d1ce69838b7b56508ac61c47a66825c7584556038319d3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('HighHeelWhatever')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
